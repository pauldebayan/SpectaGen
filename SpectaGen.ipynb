{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauldebayan/SpectaGen/blob/main/SpectaGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f66445c-d883-440c-a8de-a4815438f483",
      "metadata": {
        "tags": [],
        "id": "8f66445c-d883-440c-a8de-a4815438f483"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/pauldebayan/SpectaGen/refs/heads/main/labels.csv\n",
        "!wget https://github.com/pauldebayan/SpectaGen/raw/refs/heads/main/spectacle_dataset.zip\n",
        "!unzip spectacle_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e3920d6-851a-463c-aa73-e0db0661b045",
      "metadata": {
        "tags": [],
        "id": "5e3920d6-851a-463c-aa73-e0db0661b045"
      },
      "outputs": [],
      "source": [
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9c1700-d570-4074-b791-b547e3b74898",
      "metadata": {
        "tags": [],
        "id": "5f9c1700-d570-4074-b791-b547e3b74898"
      },
      "outputs": [],
      "source": [
        "def ImagesToDelete():\n",
        "    # To check all the images is of same shape\n",
        "    channel, height, width = 3, 512, 512\n",
        "\n",
        "    imagesToDelete = []\n",
        "\n",
        "    for i in range(1, 1000):\n",
        "        img = read_image(f'./spectacle_dataset/specs{(i+1)}.jpg')\n",
        "\n",
        "        if(img.shape[0] != channel or img.shape[1] != height or img.shape[2] != width):\n",
        "            imagesToDelete.append(f'specs{(i+1)}.jpg')\n",
        "\n",
        "    # We need to delete this images as they do not have the desired shape - [3, 256, 512]\n",
        "    return imagesToDelete\n",
        "\n",
        "print(ImagesToDelete())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d06f688-010d-46d0-9fa3-4b002eb8a47b",
      "metadata": {
        "tags": [],
        "id": "5d06f688-010d-46d0-9fa3-4b002eb8a47b"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available and move model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89f7250-cd7b-4451-b9cb-53b81be6c3d6",
      "metadata": {
        "tags": [],
        "id": "b89f7250-cd7b-4451-b9cb-53b81be6c3d6"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 20, 2)\n",
        "        self.conv2 = nn.Conv2d(20, 10, 2)\n",
        "        self.conv3 = nn.Conv2d(10, 10, 2)\n",
        "\n",
        "        self.activ = nn.LeakyReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(39690, 512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512,256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256,64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(self.activ(self.conv1(x)))\n",
        "        x = self.pool(self.activ(self.conv2(x)))\n",
        "        x = self.pool(self.activ(self.conv3(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_stack(x)\n",
        "        return x\n",
        "\n",
        "        #return x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b24aa5c-a106-48f9-bdcf-48ccd7fc690d",
      "metadata": {
        "tags": [],
        "id": "0b24aa5c-a106-48f9-bdcf-48ccd7fc690d"
      },
      "outputs": [],
      "source": [
        "class Genearator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gen_sequence = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose2d(128, 512, 3, stride=3),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 5, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 256, 3, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 256, 3, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 3, 4, stride=4),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 128, 2, 2)  # [batch_size, channels, height, width]\n",
        "        x = self.gen_sequence(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1198f0f6-0bc0-43c1-9b6e-6ad32a265d69",
      "metadata": {
        "tags": [],
        "id": "1198f0f6-0bc0-43c1-9b6e-6ad32a265d69"
      },
      "outputs": [],
      "source": [
        "generator = Genearator()\n",
        "generator = generator.to(device)\n",
        "discriminator = Discriminator()\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "print(discriminator)\n",
        "print(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074f609e-bb2d-443d-bcd2-c3af025f4b37",
      "metadata": {
        "tags": [],
        "id": "074f609e-bb2d-443d-bcd2-c3af025f4b37"
      },
      "outputs": [],
      "source": [
        "#generator.load_state_dict(torch.load('generator.pt'))\n",
        "#discriminator.load_state_dict(torch.load('discriminator.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57648597-a30c-4cae-8193-7b44d7acc800",
      "metadata": {
        "tags": [],
        "id": "57648597-a30c-4cae-8193-7b44d7acc800"
      },
      "outputs": [],
      "source": [
        "# To get the input of the linear layer in Discriminator\n",
        "\n",
        "img = read_image('./spectacle_dataset/specs1.jpg')\n",
        "print(img.shape)\n",
        "print(discriminator(img.to(device).float()))\n",
        "#39690\n",
        "#Will cause error because of batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9501821d-ea8f-4b34-9bdf-2321d2c5968b",
      "metadata": {
        "tags": [],
        "id": "9501821d-ea8f-4b34-9bdf-2321d2c5968b"
      },
      "outputs": [],
      "source": [
        "def generateNoise():\n",
        "    noise = torch.randn(1, 512)\n",
        "    return noise\n",
        "\n",
        "# Conv2d: (N-K+1)/S\n",
        "# ConvTranspose2d: (N-1)*S+K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c1bbac-0a1e-40e0-8a24-9198f5b34219",
      "metadata": {
        "tags": [],
        "id": "40c1bbac-0a1e-40e0-8a24-9198f5b34219"
      },
      "outputs": [],
      "source": [
        "noise = generateNoise()\n",
        "noise = noise.to(device)\n",
        "img = generator(noise)\n",
        "\n",
        "img = img.to(device)\n",
        "\n",
        "print(img.shape)\n",
        "plt.imshow(img.cpu().squeeze().detach().permute(1, 2, 0))\n",
        "\n",
        "print(f\"Fake image shape: {img.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1986d037-60f9-4af6-85af-c45614b079fb",
      "metadata": {
        "tags": [],
        "id": "1986d037-60f9-4af6-85af-c45614b079fb"
      },
      "outputs": [],
      "source": [
        "# Real Images - set dataloader\n",
        "class SpectDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3b4ed6-913f-4d84-be4a-14743710e433",
      "metadata": {
        "tags": [],
        "id": "fa3b4ed6-913f-4d84-be4a-14743710e433"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = SpectDataset(img_dir = 'spectacle_dataset',\n",
        "                             annotations_file = 'labels.csv',\n",
        "                             transform = transform)\n",
        "\n",
        "batch_size = 5\n",
        "dl = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b667b32e-90d9-42b9-b5ff-456fbc04f522",
      "metadata": {
        "tags": [],
        "id": "b667b32e-90d9-42b9-b5ff-456fbc04f522"
      },
      "outputs": [],
      "source": [
        "epochs = 10000000\n",
        "lr = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf456faa-52b1-4d01-873f-58b6de6756cc",
      "metadata": {
        "tags": [],
        "id": "bf456faa-52b1-4d01-873f-58b6de6756cc"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9016b5-ef57-44d5-a4e3-76482df7fe0a",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9016b5-ef57-44d5-a4e3-76482df7fe0a",
        "outputId": "e1c075e3-299e-4e81-9e70-c362648a9348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch153 Batch61: Discriminator Loss: 0.011180240660905838, Max: 0.7167648077011108, Generator Loss: 5.090524196624756, Min: 0.09839081019163132\n",
            "Epoch153 Batch62: Discriminator Loss: 0.1777801811695099, Max: 0.7167648077011108, Generator Loss: 3.417869806289673, Min: 0.09839081019163132\n",
            "Epoch153 Batch63: Discriminator Loss: 0.0983826220035553, Max: 0.7167648077011108, Generator Loss: 18.26249885559082, Min: 0.09839081019163132\n",
            "Epoch153 Batch64: Discriminator Loss: 0.11726914346218109, Max: 0.7167648077011108, Generator Loss: 7.8670759201049805, Min: 0.09839081019163132\n",
            "Epoch153 Batch65: Discriminator Loss: 0.9373670816421509, Max: 0.9373670816421509, Generator Loss: 0.89580237865448, Min: 0.09839081019163132\n",
            "Epoch153 Batch66: Discriminator Loss: 0.002864391542971134, Max: 0.9373670816421509, Generator Loss: 7.726925849914551, Min: 0.09839081019163132\n",
            "Epoch153 Batch67: Discriminator Loss: 0.0028864555060863495, Max: 0.9373670816421509, Generator Loss: 7.912465572357178, Min: 0.09839081019163132\n",
            "Epoch153 Batch68: Discriminator Loss: 0.004864860791712999, Max: 0.9373670816421509, Generator Loss: 11.101831436157227, Min: 0.09839081019163132\n",
            "Epoch153 Batch69: Discriminator Loss: 0.08138635009527206, Max: 0.9373670816421509, Generator Loss: 9.407476425170898, Min: 0.09839081019163132\n",
            "Epoch153 Batch70: Discriminator Loss: 0.3942936956882477, Max: 0.9373670816421509, Generator Loss: 12.2539644241333, Min: 0.09839081019163132\n",
            "Epoch153 Batch71: Discriminator Loss: 0.022381754592061043, Max: 0.9373670816421509, Generator Loss: 11.483308792114258, Min: 0.09839081019163132\n",
            "Epoch153 Batch72: Discriminator Loss: 0.070184625685215, Max: 0.9373670816421509, Generator Loss: 11.978557586669922, Min: 0.09839081019163132\n",
            "Epoch153 Batch73: Discriminator Loss: 0.20132333040237427, Max: 0.9373670816421509, Generator Loss: 26.527841567993164, Min: 0.09839081019163132\n",
            "Epoch153 Batch74: Discriminator Loss: 0.01183370128273964, Max: 0.9373670816421509, Generator Loss: 11.84510612487793, Min: 0.09839081019163132\n",
            "Epoch153 Batch75: Discriminator Loss: 0.009804564528167248, Max: 0.9373670816421509, Generator Loss: 26.843347549438477, Min: 0.09839081019163132\n",
            "Epoch153 Batch76: Discriminator Loss: 0.027732886373996735, Max: 0.9373670816421509, Generator Loss: 4.4219770431518555, Min: 0.09839081019163132\n",
            "Epoch153 Batch77: Discriminator Loss: 0.12927545607089996, Max: 0.9373670816421509, Generator Loss: 7.3008246421813965, Min: 0.09839081019163132\n",
            "Epoch153 Batch78: Discriminator Loss: 0.22979393601417542, Max: 0.9373670816421509, Generator Loss: 13.076205253601074, Min: 0.09839081019163132\n",
            "Epoch153 Batch79: Discriminator Loss: 0.18056844174861908, Max: 0.9373670816421509, Generator Loss: 7.789099216461182, Min: 0.09839081019163132\n",
            "Epoch153 Batch80: Discriminator Loss: 0.11268863081932068, Max: 0.9373670816421509, Generator Loss: 27.142616271972656, Min: 0.09839081019163132\n",
            "Epoch153 Batch81: Discriminator Loss: 0.15914379060268402, Max: 0.9373670816421509, Generator Loss: 4.127152442932129, Min: 0.09839081019163132\n",
            "Epoch153 Batch82: Discriminator Loss: 0.0952385738492012, Max: 0.9373670816421509, Generator Loss: 11.091792106628418, Min: 0.09839081019163132\n",
            "Epoch153 Batch83: Discriminator Loss: 0.03152552247047424, Max: 0.9373670816421509, Generator Loss: 8.191637992858887, Min: 0.09839081019163132\n",
            "Epoch153 Batch84: Discriminator Loss: 0.15976209938526154, Max: 0.9373670816421509, Generator Loss: 7.902543544769287, Min: 0.09839081019163132\n",
            "Epoch153 Batch85: Discriminator Loss: 0.007737896870821714, Max: 0.9373670816421509, Generator Loss: 9.555766105651855, Min: 0.09839081019163132\n",
            "Epoch153 Batch86: Discriminator Loss: 0.010151751339435577, Max: 0.9373670816421509, Generator Loss: 15.846903800964355, Min: 0.09839081019163132\n",
            "Epoch153 Batch87: Discriminator Loss: 0.02370881289243698, Max: 0.9373670816421509, Generator Loss: 3.924616813659668, Min: 0.09839081019163132\n",
            "Epoch153 Batch88: Discriminator Loss: 0.0016388801159337163, Max: 0.9373670816421509, Generator Loss: 8.36871337890625, Min: 0.09839081019163132\n",
            "Epoch153 Batch89: Discriminator Loss: 0.03428764268755913, Max: 0.9373670816421509, Generator Loss: 11.676292419433594, Min: 0.09839081019163132\n",
            "Epoch153 Batch90: Discriminator Loss: 0.8222483396530151, Max: 0.9373670816421509, Generator Loss: 0.5867229104042053, Min: 0.09839081019163132\n",
            "Epoch153 Batch91: Discriminator Loss: 0.10140956193208694, Max: 0.9373670816421509, Generator Loss: 12.30448055267334, Min: 0.09839081019163132\n",
            "Epoch153 Batch92: Discriminator Loss: 0.004781595431268215, Max: 0.9373670816421509, Generator Loss: 6.087832927703857, Min: 0.09839081019163132\n",
            "Epoch153 Batch93: Discriminator Loss: 0.0027842780109494925, Max: 0.9373670816421509, Generator Loss: 6.256038188934326, Min: 0.09839081019163132\n",
            "Epoch153 Batch94: Discriminator Loss: 0.07275675237178802, Max: 0.9373670816421509, Generator Loss: 3.531956911087036, Min: 0.09839081019163132\n",
            "Epoch153 Batch95: Discriminator Loss: 0.254047691822052, Max: 0.9373670816421509, Generator Loss: 3.1342763900756836, Min: 0.09839081019163132\n",
            "Epoch153 Batch96: Discriminator Loss: 0.3699238896369934, Max: 0.9373670816421509, Generator Loss: 3.1359994411468506, Min: 0.09839081019163132\n",
            "Epoch153 Batch97: Discriminator Loss: 0.00803016684949398, Max: 0.9373670816421509, Generator Loss: 6.320770740509033, Min: 0.09839081019163132\n",
            "Epoch153 Batch98: Discriminator Loss: 0.09478901326656342, Max: 0.9373670816421509, Generator Loss: 4.909513473510742, Min: 0.09839081019163132\n",
            "Epoch153 Batch99: Discriminator Loss: 0.26523807644844055, Max: 0.9373670816421509, Generator Loss: 10.331326484680176, Min: 0.09839081019163132\n",
            "Epoch153 Batch100: Discriminator Loss: 0.09401585161685944, Max: 0.9373670816421509, Generator Loss: 13.396062850952148, Min: 0.09839081019163132\n",
            "Epoch153 Batch101: Discriminator Loss: 0.12247981876134872, Max: 0.9373670816421509, Generator Loss: 10.884937286376953, Min: 0.09839081019163132\n",
            "Epoch153 Batch102: Discriminator Loss: 0.25208744406700134, Max: 0.9373670816421509, Generator Loss: 11.842049598693848, Min: 0.09839081019163132\n",
            "Epoch153 Batch103: Discriminator Loss: 0.008106865920126438, Max: 0.9373670816421509, Generator Loss: 4.5374226570129395, Min: 0.09839081019163132\n",
            "Epoch153 Batch104: Discriminator Loss: 0.04377453774213791, Max: 0.9373670816421509, Generator Loss: 10.117194175720215, Min: 0.09839081019163132\n",
            "Epoch153 Batch105: Discriminator Loss: 0.005121997091919184, Max: 0.9373670816421509, Generator Loss: 4.862336158752441, Min: 0.09839081019163132\n",
            "Epoch153 Batch106: Discriminator Loss: 1.2213479280471802, Max: 1.2213479280471802, Generator Loss: 0.23971055448055267, Min: 0.09839081019163132\n",
            "Epoch153 Batch107: Discriminator Loss: 0.1740487664937973, Max: 1.2213479280471802, Generator Loss: 9.876890182495117, Min: 0.09839081019163132\n",
            "Epoch153 Batch108: Discriminator Loss: 0.0234422218054533, Max: 1.2213479280471802, Generator Loss: 10.279486656188965, Min: 0.09839081019163132\n",
            "Epoch153 Batch109: Discriminator Loss: 0.12222789227962494, Max: 1.2213479280471802, Generator Loss: 10.027578353881836, Min: 0.09839081019163132\n",
            "Epoch153 Batch110: Discriminator Loss: 0.027116850018501282, Max: 1.2213479280471802, Generator Loss: 9.349665641784668, Min: 0.09839081019163132\n",
            "Epoch153 Batch111: Discriminator Loss: 0.21341834962368011, Max: 1.2213479280471802, Generator Loss: 9.441244125366211, Min: 0.09839081019163132\n",
            "Epoch153 Batch112: Discriminator Loss: 0.07060912251472473, Max: 1.2213479280471802, Generator Loss: 9.113518714904785, Min: 0.09839081019163132\n",
            "Epoch153 Batch113: Discriminator Loss: 0.0014146293979138136, Max: 1.2213479280471802, Generator Loss: 4.15948486328125, Min: 0.09839081019163132\n",
            "Epoch153 Batch114: Discriminator Loss: 0.035601258277893066, Max: 1.2213479280471802, Generator Loss: 8.253961563110352, Min: 0.09839081019163132\n",
            "Epoch153 Batch115: Discriminator Loss: 0.23625296354293823, Max: 1.2213479280471802, Generator Loss: 11.278286933898926, Min: 0.09839081019163132\n",
            "Epoch153 Batch116: Discriminator Loss: 0.08260159939527512, Max: 1.2213479280471802, Generator Loss: 9.76678466796875, Min: 0.09839081019163132\n",
            "Epoch153 Batch117: Discriminator Loss: 0.0016168035799637437, Max: 1.2213479280471802, Generator Loss: 7.065960884094238, Min: 0.09839081019163132\n",
            "Epoch153 Batch118: Discriminator Loss: 0.35086727142333984, Max: 1.2213479280471802, Generator Loss: 2.8574275970458984, Min: 0.09839081019163132\n",
            "Epoch153 Batch119: Discriminator Loss: 0.0004299768479540944, Max: 1.2213479280471802, Generator Loss: 5.685207843780518, Min: 0.09839081019163132\n",
            "Epoch153 Batch120: Discriminator Loss: 0.04555448144674301, Max: 1.2213479280471802, Generator Loss: 1.7472639083862305, Min: 0.09839081019163132\n",
            "Epoch153 Batch121: Discriminator Loss: 0.002292682882398367, Max: 1.2213479280471802, Generator Loss: 13.934226036071777, Min: 0.09839081019163132\n",
            "Epoch153 Batch122: Discriminator Loss: 0.0016901905182749033, Max: 1.2213479280471802, Generator Loss: 11.540075302124023, Min: 0.09839081019163132\n",
            "Epoch153 Batch123: Discriminator Loss: 0.0004428133543115109, Max: 1.2213479280471802, Generator Loss: 14.231612205505371, Min: 0.09839081019163132\n",
            "Epoch153 Batch124: Discriminator Loss: 0.022508341819047928, Max: 1.2213479280471802, Generator Loss: 2.792363405227661, Min: 0.09839081019163132\n",
            "Epoch153 Batch125: Discriminator Loss: 0.15795382857322693, Max: 1.2213479280471802, Generator Loss: 13.358720779418945, Min: 0.09839081019163132\n",
            "Epoch153 Batch126: Discriminator Loss: 0.15645359456539154, Max: 1.2213479280471802, Generator Loss: 1.4972134828567505, Min: 0.09839081019163132\n",
            "Epoch153 Batch127: Discriminator Loss: 0.04099028930068016, Max: 1.2213479280471802, Generator Loss: 3.668654441833496, Min: 0.09839081019163132\n",
            "Epoch153 Batch128: Discriminator Loss: 1.8997724056243896, Max: 1.8997724056243896, Generator Loss: 0.018001867458224297, Min: 0.018001867458224297\n",
            "Epoch153 Batch129: Discriminator Loss: 0.9381633996963501, Max: 1.8997724056243896, Generator Loss: 0.9234393835067749, Min: 0.018001867458224297\n",
            "Epoch153 Batch130: Discriminator Loss: 0.014416530728340149, Max: 1.8997724056243896, Generator Loss: 14.280226707458496, Min: 0.018001867458224297\n",
            "Epoch153 Batch131: Discriminator Loss: 0.3620626926422119, Max: 1.8997724056243896, Generator Loss: 4.8298115730285645, Min: 0.018001867458224297\n",
            "Epoch153 Batch132: Discriminator Loss: 0.20192839205265045, Max: 1.8997724056243896, Generator Loss: 9.140814781188965, Min: 0.018001867458224297\n",
            "Epoch153 Batch133: Discriminator Loss: 0.0030197349842637777, Max: 1.8997724056243896, Generator Loss: 5.340380668640137, Min: 0.018001867458224297\n",
            "Epoch153 Batch134: Discriminator Loss: 0.031339455395936966, Max: 1.8997724056243896, Generator Loss: 5.413971900939941, Min: 0.018001867458224297\n",
            "Epoch153 Batch135: Discriminator Loss: 0.005369615275412798, Max: 1.8997724056243896, Generator Loss: 9.536327362060547, Min: 0.018001867458224297\n",
            "Epoch153 Batch136: Discriminator Loss: 0.42644771933555603, Max: 1.8997724056243896, Generator Loss: 8.859981536865234, Min: 0.018001867458224297\n",
            "Epoch153 Batch137: Discriminator Loss: 0.22000053524971008, Max: 1.8997724056243896, Generator Loss: 13.335826873779297, Min: 0.018001867458224297\n",
            "Epoch153 Batch138: Discriminator Loss: 0.4500073790550232, Max: 1.8997724056243896, Generator Loss: 13.026656150817871, Min: 0.018001867458224297\n",
            "Epoch153 Batch139: Discriminator Loss: 0.1088055744767189, Max: 1.8997724056243896, Generator Loss: 13.085240364074707, Min: 0.018001867458224297\n",
            "Epoch153 Batch140: Discriminator Loss: 0.7542769908905029, Max: 1.8997724056243896, Generator Loss: 14.07232666015625, Min: 0.018001867458224297\n",
            "Epoch153 Batch141: Discriminator Loss: 0.30671384930610657, Max: 1.8997724056243896, Generator Loss: 13.599042892456055, Min: 0.018001867458224297\n",
            "Epoch153 Batch142: Discriminator Loss: 0.26706019043922424, Max: 1.8997724056243896, Generator Loss: 14.802041053771973, Min: 0.018001867458224297\n",
            "Epoch153 Batch143: Discriminator Loss: 0.32742124795913696, Max: 1.8997724056243896, Generator Loss: 12.146611213684082, Min: 0.018001867458224297\n",
            "Epoch153 Batch144: Discriminator Loss: 0.27131086587905884, Max: 1.8997724056243896, Generator Loss: 14.203804969787598, Min: 0.018001867458224297\n",
            "Epoch153 Batch145: Discriminator Loss: 0.11769626289606094, Max: 1.8997724056243896, Generator Loss: 13.978048324584961, Min: 0.018001867458224297\n",
            "Epoch153 Batch146: Discriminator Loss: 0.17754632234573364, Max: 1.8997724056243896, Generator Loss: 12.020378112792969, Min: 0.018001867458224297\n",
            "Epoch153 Batch147: Discriminator Loss: 0.1263173371553421, Max: 1.8997724056243896, Generator Loss: 6.756474018096924, Min: 0.018001867458224297\n",
            "Epoch153 Batch148: Discriminator Loss: 0.4548566937446594, Max: 1.8997724056243896, Generator Loss: 11.596760749816895, Min: 0.018001867458224297\n",
            "Epoch153 Batch149: Discriminator Loss: 0.5112296342849731, Max: 1.8997724056243896, Generator Loss: 9.820198059082031, Min: 0.018001867458224297\n",
            "Epoch153 Batch150: Discriminator Loss: 0.07900212705135345, Max: 1.8997724056243896, Generator Loss: 5.79644775390625, Min: 0.018001867458224297\n",
            "Epoch153 Batch151: Discriminator Loss: 0.005243625957518816, Max: 1.8997724056243896, Generator Loss: 8.20430850982666, Min: 0.018001867458224297\n",
            "Epoch153 Batch152: Discriminator Loss: 0.021868867799639702, Max: 1.8997724056243896, Generator Loss: 10.641166687011719, Min: 0.018001867458224297\n",
            "Epoch153 Batch153: Discriminator Loss: 0.01372127141803503, Max: 1.8997724056243896, Generator Loss: 8.875288009643555, Min: 0.018001867458224297\n",
            "Epoch153 Batch154: Discriminator Loss: 0.3302757740020752, Max: 1.8997724056243896, Generator Loss: 9.745112419128418, Min: 0.018001867458224297\n",
            "Epoch153 Batch155: Discriminator Loss: 0.011404773220419884, Max: 1.8997724056243896, Generator Loss: 4.032188415527344, Min: 0.018001867458224297\n",
            "Epoch153 Batch156: Discriminator Loss: 0.049006011337041855, Max: 1.8997724056243896, Generator Loss: 10.16762638092041, Min: 0.018001867458224297\n"
          ]
        }
      ],
      "source": [
        "# Implementing GANs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "\n",
        "\n",
        "    batch_counter = 1\n",
        "    dis_loss_max = 0\n",
        "    gen_loss_min = 100\n",
        "\n",
        "    for real_img, real_label in dl:\n",
        "\n",
        "        real_img = real_img.to(device)\n",
        "        real_label = torch.tensor(1).float().to(device)\n",
        "\n",
        "        noise = generateNoise().to(device)\n",
        "        fake_img = generator(noise).to(device)\n",
        "        fake_label = torch.tensor(0).float().to(device)\n",
        "\n",
        "\n",
        "        #Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        loss_G = loss_fn(discriminator(fake_img).squeeze(), real_label)\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        #Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        fake_loss = loss_fn(discriminator(fake_img.detach()).squeeze(), fake_label)\n",
        "        real_loss = loss_fn(discriminator(real_img).mean().squeeze(), real_label)\n",
        "        loss_D = (fake_loss+real_loss)/2\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        gen_loss = loss_G.item()\n",
        "        dis_loss = loss_D.item()\n",
        "\n",
        "        if (gen_loss < gen_loss_min):\n",
        "            gen_loss_min = gen_loss\n",
        "\n",
        "        if (dis_loss > dis_loss_max):\n",
        "            dis_loss_max = dis_loss\n",
        "\n",
        "        print(f\"Epoch{epoch+1} Batch{batch_counter}: Discriminator Loss: {dis_loss}, Max: {dis_loss_max}, Generator Loss: {gen_loss}, Min: {gen_loss_min}\")\n",
        "        batch_counter += 1\n",
        "\n",
        "\n",
        "    if ((epoch+1)%1) == 0:\n",
        "        noise = generateNoise()\n",
        "        noise = noise.to(device)\n",
        "        fake_img = generator(noise)\n",
        "        fake_img = fake_img.to(device)\n",
        "        torchvision.utils.save_image(fake_img, 'generated.jpg')\n",
        "        plt.imshow(fake_img.cpu().squeeze().detach().permute(1, 2, 0))\n",
        "        plt.show()\n",
        "        torch.save(generator.state_dict(), 'generator.pt')\n",
        "        torch.save(discriminator.state_dict(), 'discriminator.pt')\n",
        "        #playsound('epoch10.mp3')\n",
        "\n",
        "    if gen_loss > 100:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sagemaker-distribution:Python",
      "language": "python",
      "name": "conda-env-sagemaker-distribution-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}